{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a7f1eae",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b21e72",
   "metadata": {},
   "source": [
    "The data appears to be relatively clean. No empty cells. Data types are consistent. Columns Index, Sentiment, Text...\n",
    "\n",
    "The data will need to be processed to remove numbers and special characters as well as lemmatized and tokenized to used by classification models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de50f4c",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1a38bc",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fe5d4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Index  Sentiment                                               Text\n",
      "781974    781974          0  i did not know that @PaulaAbdul had a step bro...\n",
      "937737    937737          1  @sheila97 bamburi beach , travellers , ocean s...\n",
      "907828    907828          1  @jesterjay SWINE FLU. Some family just came ba...\n",
      "784628    784628          0            The Kids video seriously freaks me out \n",
      "662460    662460          0                                Back is hurting.  x\n",
      "...          ...        ...                                                ...\n",
      "933141    933141          1  @fii111 lets DO IT! move to NY at the end of t...\n",
      "1007347  1007347          1  good morning! tis a beautiful day in sunny lon...\n",
      "80444      80444          0                      Have to redo my whole itunes \n",
      "772632    772632          0  Finally got MSN IM to let me sign on for the f...\n",
      "989497    989497          1  @Lifelists Poor you. I had root canal twice la...\n",
      "\n",
      "[104858 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read data sets\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# Get 10% of the rows because my computer cannot handle the whole dataset\n",
    "train = train.sample(frac=0.10, random_state=42)\n",
    "\n",
    "print(train)\n",
    "\n",
    "# # Counting number of 1s in Sentiment\n",
    "# num_positive = (train['Sentiment'] == 1).sum()\n",
    "# print(num_positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779810b6",
   "metadata": {},
   "source": [
    "## Convert to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e466150e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Text'] = train['Text'].apply(lambda x: x.lower())\n",
    "test['Text'] = test['Text'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574b54e7",
   "metadata": {},
   "source": [
    "## Remove numbers and special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b867e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No rows in Text contain numbers or special characters.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def remove_special_chars(text):\n",
    "    # Replace all non-word characters with empty string\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    # Replace all digits with empty string\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "    return text\n",
    "\n",
    "train['Text'] = train['Text'].apply(remove_special_chars)\n",
    "test['Text'] = test['Text'].apply(remove_special_chars)\n",
    "\n",
    "# Check if numbers still exist\n",
    "pattern = r'[0-9@#$]'\n",
    "\n",
    "# Loop through columns in dataframe\n",
    "for col in train.columns:\n",
    "    # Check if column is of object type (i.e., contains text data)\n",
    "    if train[col].dtype == 'O':\n",
    "        # Use regex to check if column contains numbers or special characters\n",
    "        if train[col].str.contains(pattern).any():\n",
    "            # If the column contains numbers or special characters, display the rows where they occur\n",
    "            print(f\"Rows in {col} containing numbers or special characters:\")\n",
    "            print(train[train[col].str.contains(pattern)])\n",
    "        else:\n",
    "            print(f\"No rows in {col} contain numbers or special characters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fa740f",
   "metadata": {},
   "source": [
    "## Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08105995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will not be removing stop words to preserve semantics, but below is the code\n",
    "\n",
    "# from nltk.corpus import stopwords\n",
    "\n",
    "# stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# def remove_stopwords(text):\n",
    "#     return \" \".join([word for word in text.split() if word not in stop_words])\n",
    "\n",
    "# train['Text'] = train['Text'].apply(remove_stopwords)\n",
    "# test['Text'] = test['Text'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca37ac0",
   "metadata": {},
   "source": [
    "## Stemming or Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57616c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.stem import PorterStemmer\n",
    "\n",
    "# stemmer = PorterStemmer()\n",
    "\n",
    "# def stemming(text):\n",
    "#     return \" \".join([stemmer.stem(word) for word in text.split()])\n",
    "\n",
    "# train['Text'] = train['Text'].apply(stemming)\n",
    "\n",
    "# train.head()\n",
    "\n",
    "\n",
    "#I use lemmatization to preserve meaning\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# function to apply lemmatization to text\n",
    "def lemmatize_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    lemmatized_text = ' '.join([lemmatizer.lemmatize(token) for token in tokens])\n",
    "    return lemmatized_text\n",
    "\n",
    "# apply lemmatization to the 'text' column of the DataFrame\n",
    "train['Text'] = train['Text'].apply(lemmatize_text)\n",
    "test['Text'] = test['Text'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b771acd8",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "600fc33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "train['Tokens'] = train['Text'].apply(word_tokenize)\n",
    "test['Tokens'] = test['Text'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b89b3f",
   "metadata": {},
   "source": [
    "# Linguistic Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f82f1d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Set y_train and y_test\n",
    "y_train = train['Sentiment']\n",
    "y_test = test['Sentiment']\n",
    "\n",
    "# Create a bag of words representation\n",
    "count_vectorizer = CountVectorizer()\n",
    "X_train_bow = count_vectorizer.fit_transform(train['Text'])\n",
    "X_test_bow = count_vectorizer.transform(test['Text'])\n",
    "\n",
    "# Create TF-IDF features\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(train['Text'])\n",
    "X_test_tfidf = tfidf_vectorizer.transform(test['Text'])\n",
    "\n",
    "# Create feature vectors word2vec\n",
    "merged_df = pd.concat([train, test], axis=0)\n",
    "w2v_model = Word2Vec(sentences=merged_df['Tokens'], vector_size=100, window=5, min_count=2, workers=4)\n",
    "\n",
    "X = []\n",
    "for tokens in merged_df['Tokens']:\n",
    "    vector = []\n",
    "    for token in tokens:\n",
    "        if token in w2v_model.wv:\n",
    "            vector.append(w2v_model.wv[token])\n",
    "    if vector:\n",
    "        X.append(np.mean(vector, axis=0))\n",
    "    else:\n",
    "        X.append([0] * 100)\n",
    "    \n",
    "X = np.array(X, dtype=object)\n",
    "\n",
    "# Create target vector\n",
    "y = merged_df['Sentiment']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train_w2v, X_test_w2v, y_train_w2v, y_test_w2v = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b75e3cd",
   "metadata": {},
   "source": [
    "# Sentiment Classification Model + Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b85036",
   "metadata": {},
   "source": [
    "## Comparing all 3 features on Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d333ef19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------\n",
      "LR bag of words accuracy: 0.7214484679665738\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.95      0.77       177\n",
      "           1       0.91      0.50      0.65       182\n",
      "\n",
      "    accuracy                           0.72       359\n",
      "   macro avg       0.78      0.72      0.71       359\n",
      "weighted avg       0.78      0.72      0.71       359\n",
      "\n",
      "-----------------------------------------------------\n",
      "LR tfidf accuracy: 0.7214484679665738\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.95      0.77       177\n",
      "           1       0.92      0.49      0.64       182\n",
      "\n",
      "    accuracy                           0.72       359\n",
      "   macro avg       0.78      0.72      0.71       359\n",
      "weighted avg       0.78      0.72      0.71       359\n",
      "\n",
      "-----------------------------------------------------\n",
      "LR w2v accuracy: 0.808544003041247\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.96      0.88     16112\n",
      "           1       0.69      0.33      0.45      4932\n",
      "\n",
      "    accuracy                           0.81     21044\n",
      "   macro avg       0.76      0.64      0.67     21044\n",
      "weighted avg       0.79      0.81      0.78     21044\n",
      "\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# train LR w/ bow\n",
    "lr_bow = LogisticRegression(max_iter=1000)\n",
    "lr_bow.fit(X_train_bow, y_train)\n",
    "\n",
    "# train LR w/ tfidf\n",
    "lr_tfidf = LogisticRegression(max_iter=1000)\n",
    "lr_tfidf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# train LR w/ w2v\n",
    "lr_w2v = LogisticRegression(max_iter=1000)\n",
    "lr_w2v.fit(X_train_w2v, y_train_w2v)\n",
    "\n",
    "\n",
    "# evaluate the logistic regression classifier on the test data\n",
    "y_pred_lr_bow = lr_bow.predict(X_test_bow)\n",
    "lr_accuracy_bow = accuracy_score(y_test, y_pred_lr_bow)\n",
    "report_bow = classification_report(y_test, y_pred_lr_bow)\n",
    "\n",
    "y_pred_lr_tfidf = lr_tfidf.predict(X_test_tfidf)\n",
    "lr_accuracy_tfidf = accuracy_score(y_test, y_pred_lr_tfidf)\n",
    "report_tfidf = classification_report(y_test, y_pred_lr_tfidf)\n",
    "\n",
    "y_pred_lr_w2v = lr_w2v.predict(X_test_w2v)\n",
    "lr_accuracy_w2v = accuracy_score(y_test_w2v, y_pred_lr_w2v)\n",
    "report_w2v = classification_report(y_test_w2v, y_pred_lr_w2v)\n",
    "\n",
    "\n",
    "print('-----------------------------------------------------')\n",
    "print(\"LR bag of words accuracy:\", lr_accuracy_bow)\n",
    "print(report_bow)\n",
    "print('-----------------------------------------------------')\n",
    "print(\"LR tfidf accuracy:\", lr_accuracy_tfidf)\n",
    "print(report_tfidf)\n",
    "print('-----------------------------------------------------')\n",
    "print(\"LR w2v accuracy:\", lr_accuracy_w2v)\n",
    "print(report_w2v)\n",
    "print('-----------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ffd885",
   "metadata": {},
   "source": [
    "## Comparing all 4 models using W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1e3167b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------\n",
      "LR accuracy: 0.808544003041247\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.96      0.88     16112\n",
      "           1       0.69      0.33      0.45      4932\n",
      "\n",
      "    accuracy                           0.81     21044\n",
      "   macro avg       0.76      0.64      0.67     21044\n",
      "weighted avg       0.79      0.81      0.78     21044\n",
      "\n",
      "-----------------------------------------------------\n",
      "SVM accuracy: 0.808734080973199\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.98      0.89     16112\n",
      "           1       0.77      0.26      0.39      4932\n",
      "\n",
      "    accuracy                           0.81     21044\n",
      "   macro avg       0.79      0.62      0.64     21044\n",
      "weighted avg       0.80      0.81      0.77     21044\n",
      "\n",
      "-----------------------------------------------------\n",
      "Naive Bayes accuracy: 0.7656339099030602\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87     16112\n",
      "           1       0.00      0.00      0.00      4932\n",
      "\n",
      "    accuracy                           0.77     21044\n",
      "   macro avg       0.38      0.50      0.43     21044\n",
      "weighted avg       0.59      0.77      0.66     21044\n",
      "\n",
      "-----------------------------------------------------\n",
      "Random Forest accuracy: 0.7999429766204144\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.98      0.88     16112\n",
      "           1       0.74      0.23      0.35      4932\n",
      "\n",
      "    accuracy                           0.80     21044\n",
      "   macro avg       0.77      0.60      0.61     21044\n",
      "weighted avg       0.79      0.80      0.76     21044\n",
      "\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# Train LR classifier\n",
    "lr_classifier = LogisticRegression(max_iter=1000)\n",
    "lr_classifier.fit(X_train_w2v, y_train_w2v)\n",
    "\n",
    "# Train SVM classifier\n",
    "svm_classifier = SVC()\n",
    "svm_classifier.fit(X_train_w2v, y_train_w2v)\n",
    "\n",
    "# Train Naive Bayes classifier\n",
    "clf = Pipeline([('Normalizing',MinMaxScaler()),('MultinomialNB',MultinomialNB())])\n",
    "clf.fit(X_train_w2v, y_train_w2v) \n",
    "\n",
    "# Train Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier()\n",
    "rf_classifier.fit(X_train_w2v, y_train_w2v)\n",
    "\n",
    "\n",
    "# Make predictions and evaluate model performance\n",
    "y_pred_lr = lr_classifier.predict(X_test_w2v)\n",
    "lr_accuracy = accuracy_score(y_test_w2v, y_pred_lr)\n",
    "report_lr = classification_report(y_test_w2v, y_pred_lr, zero_division=0)\n",
    "\n",
    "y_pred_svm = svm_classifier.predict(X_test_w2v)\n",
    "svm_accuracy = accuracy_score(y_test_w2v, y_pred_svm)\n",
    "report_svm = classification_report(y_test_w2v, y_pred_svm, zero_division=0)\n",
    "\n",
    "y_pred_bayes = clf.predict(X_test_w2v)\n",
    "bayes_accuracy = accuracy_score(list(y_test_w2v), y_pred_bayes)\n",
    "report_bayes = classification_report(y_test_w2v, y_pred_bayes, zero_division=0)\n",
    "\n",
    "y_pred_rf = rf_classifier.predict(X_test_w2v)\n",
    "rf_accuracy = accuracy_score(y_test_w2v, y_pred_rf)\n",
    "report_rf = classification_report(y_test_w2v, y_pred_rf, zero_division=0)\n",
    "\n",
    "\n",
    "# Print results\n",
    "print('-----------------------------------------------------')\n",
    "print(\"LR accuracy:\", lr_accuracy)\n",
    "print(report_lr)\n",
    "print('-----------------------------------------------------')\n",
    "print(\"SVM accuracy:\", svm_accuracy)\n",
    "print(report_svm)\n",
    "print('-----------------------------------------------------')\n",
    "print('Naive Bayes accuracy:', bayes_accuracy)\n",
    "print(report_bayes)\n",
    "print('-----------------------------------------------------')\n",
    "print(\"Random Forest accuracy:\", rf_accuracy)\n",
    "print(report_rf)\n",
    "print('-----------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475fcd45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
